{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiewanzhen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:47: DeprecationWarning: use options instead of chrome_options\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql.cursors\n",
    "import time \n",
    "import os\n",
    "import urllib.request\n",
    "from datetime import date\n",
    "today =str(date.today())\n",
    "#today ='2020-02-09'\n",
    "from docx import Document\n",
    "\n",
    "\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='asd273321',\n",
    "                             db='new_media',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "\n",
    "options = Options()\n",
    "options.experimental_options[\"prefs\"] = {'profile.default_content_settings' : {\"images\":2},   \n",
    "                                         'profile.managed_default_content_settings' : {\"images\":2}}\n",
    "\n",
    "\n",
    "document = Document()\n",
    "document.add_heading(today + '新媒體文章資料爬取', 0)\n",
    "table = document.add_table(rows=1, cols=4)\n",
    "\n",
    "hdr_cells = table.rows[0].cells\n",
    "hdr_cells[0].text = '標題'\n",
    "hdr_cells[1].text = '分享數'\n",
    "hdr_cells[2].text = 'Hastag'\n",
    "hdr_cells[3].text = '網站'\n",
    "\n",
    "# row_cells = table.add_row().cells\n",
    "# row_cells[0].text = ''\n",
    "# row_cells[1].text = ''\n",
    "# row_cells[2].text = ''\n",
    "# row_cells[3].text = ''\n",
    "\n",
    "\n",
    "\n",
    "#把圖片關掉\n",
    "\n",
    "driver = webdriver.Chrome(os.getcwd()+'/chromedriver80', chrome_options=options)\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        for i in range(1, 3):\n",
    "            driver.get('https://www.inside.com.tw/?page='+ str(i) )\n",
    "            sourceCode = BeautifulSoup(driver.page_source)\n",
    "            article_box = sourceCode.select('div.post_list-grid_style')[0]\n",
    "            articles = article_box.select('div.post_list_item')\n",
    "            for article in articles:\n",
    "                title = article.select('h3.post_title')[0].text\n",
    "                date = article.select('li.post_date')[0].text.strip().replace('/', '-')\n",
    "                tags = article.select('a.hero_slide_tag')\n",
    "                #製作變數＿塞進ＴＡＧ\n",
    "                tags_string = ''\n",
    "                for tag in tags:\n",
    "                    tags_string += tag.text + ', '\n",
    "                if today == date:\n",
    "                    print(title)\n",
    "                    print(date)\n",
    "                    print(tags_string)\n",
    "                    \n",
    "                    row_cells = table.add_row().cells\n",
    "                    row_cells[0].text = title\n",
    "                    row_cells[1].text = ''\n",
    "                    row_cells[2].text = tags_string\n",
    "                    row_cells[3].text = 'Inside'\n",
    "                    \n",
    "                    sql = '''\n",
    "                    INSERT INTO `new_media`.`articles` (`title`, `date`, `tags`, `brand`)\n",
    "                    VALUES('{}', '{}', '{}', '{}')\n",
    "                    '''.format(title, date, tags_string, 'inside')\n",
    "                    cursor.execute(sql)\n",
    "                    connection.commit()\n",
    "                    \n",
    "            driver.get('https://technews.tw/page/'+ str(i)+ '/')\n",
    "            sourceCode = BeautifulSoup(driver.page_source)\n",
    "            article_box = sourceCode.select('div#content')[0]\n",
    "            articles = article_box.select('header.entry-header')\n",
    "            for article in articles:\n",
    "                title = article.select('h1.entry-title')[0].text\n",
    "                date = article.select('span.body')[1].text.strip().replace(' 年 ','-').replace(' 月 ', '-').replace(' 日 ', '-')\n",
    "                date = date[0:10]\n",
    "                #tags = article.select('a[href*=\"category\"]')\n",
    "                tags = article.select('span.body')[2].select('a')\n",
    "                iframe = article.select('iframe')[1]\n",
    "                response = urllib.request.urlopen(iframe.attrs['src'])\n",
    "                iframe_soup = BeautifulSoup(response)\n",
    "                share = iframe_soup.select('span#u_0_2')[0].text\n",
    "                #製作變數＿塞進ＴＡＧ\n",
    "                tags_string = ''\n",
    "                for tag in tags:\n",
    "                    tags_string += tag.text + ', '\n",
    "                if today == date:\n",
    "                    print(title)\n",
    "                    print(date)\n",
    "                    print(tags_string)\n",
    "                    print(share)\n",
    "                    \n",
    "                    \n",
    "                    row_cells = table.add_row().cells\n",
    "                    row_cells[0].text = title\n",
    "                    row_cells[1].text = share\n",
    "                    row_cells[2].text = tags_string\n",
    "                    row_cells[3].text = 'technews'\n",
    "                    \n",
    "                    sql ='''\n",
    "                    INSERT INTO `new_media`.`articles` (`title`, `date`, `tags`, `share`, `brand`)\n",
    "                    VALUES('{}', '{}', '{}', '{}', '{}')\n",
    "                    '''.format(title, date, tags_string, share, 'technews')\n",
    "                    cursor.execute(sql)\n",
    "                    connection.commit()\n",
    "                    \n",
    "    \n",
    "        driver.get('https://buzzorange.com/techorange/')\n",
    "        for i in range(1, 4): \n",
    "            driver.execute_script(\"window.scrollTo(0, documemt.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "        sourceCode = BeautifulSoup(driver.page_source)\n",
    "        article_box = sourceCode.select('main#main')[0]\n",
    "        articles = article_box.select('article')\n",
    "        for article in articles:\n",
    "            title = article.select('h4.entry-title')[0].text\n",
    "            date = article.select('time.entry-date')[0].text.strip().replace('/', '-')\n",
    "            share = article.select('span.shareCount')[0].text\n",
    "                        #2k的k用字串的方式抓取<type=str> 需轉換成福點數\n",
    "            if share.find('K') != -1:\n",
    "                share = float(share.split(' ')[0]) * 1000\n",
    "            else:\n",
    "                share = share.split(' ')[0]\n",
    "\n",
    "            if today == date:\n",
    "                print(title)\n",
    "                print(date)\n",
    "                print(share)\n",
    "                \n",
    "                row_cells = table.add_row().cells\n",
    "                row_cells[0].text = title\n",
    "                row_cells[1].text = share\n",
    "                row_cells[2].text = ''\n",
    "                row_cells[3].text = 'techorange'\n",
    "\n",
    "                sql = '''\n",
    "                INSERT INTO `new_media`.`articles` (`title`, `date`, `share`, `brand`)\n",
    "                VALUES('{}', '{}',  '{}', '{}')\n",
    "                '''.format(title, date, share, 'techorange')\n",
    "                cursor.execute(sql)\n",
    "                connection.commit()\n",
    "                \n",
    "                \n",
    "    document.save(today + '爬取資料.docx')\n",
    "    connection.close()\n",
    "    driver.close()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    connection.close()\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-25\n"
     ]
    }
   ],
   "source": [
    "a = '2019 年 12 月 25 日 9:00'\n",
    "date = a.replace(' 年 ','-').replace(' 月 ','-').replace(' 日 ', '-')\n",
    "print(date[0:10])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/83/c66a1934ed5ed8ab1dbb9931f1779079f8bca0f6bbc5793c06c4b5e7d671/python-docx-0.8.10.tar.gz (5.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.5MB 2.6MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in /Users/xiewanzhen/anaconda3/lib/python3.7/site-packages (from python-docx) (4.2.5)\n",
      "Building wheels for collected packages: python-docx\n",
      "  Running setup.py bdist_wheel for python-docx ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/xiewanzhen/Library/Caches/pip/wheels/18/0b/a0/1dd62ff812c857c9e487f27d80d53d2b40531bec1acecfa47b\n",
      "Successfully built python-docx\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-0.8.10\n"
     ]
    }
   ],
   "source": [
    "#!pip install python-docx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
